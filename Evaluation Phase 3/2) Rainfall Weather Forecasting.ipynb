{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87de5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imp libs:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Algorithms\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Importing metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26345c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = 'https://raw.githubusercontent.com/dsrscientist/dataset3/main/weatherAUS.csv'\n",
    "df = pd.read_csv(file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ea63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First 10 rows')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Last 10 rows')\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d034a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e55f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee63662",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data = df.isnull().sum()\n",
    "null_data.sort_values(ascending=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e53f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c91791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "8425-3490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0448cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df.describe().T\n",
    "desc['range']=desc['max']-desc['min']\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fe5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50025327",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc[['min','mean','max','range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"EXPLORATORY DATA ANALYSIS\n",
    "\n",
    "PROJECT NAME RAINFALL PREDICTION WEATHER FORECASTING\n",
    "\n",
    "Dataset contains 8425 and 23 columns.\n",
    "\n",
    "Column names mentioned below\n",
    "    ['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',\n",
    "       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',\n",
    "       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',\n",
    "       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',\n",
    "       'Temp3pm', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "Data type of columns mentioned below:\n",
    "            Date              object\n",
    "        Location          object\n",
    "        MinTemp          float64\n",
    "        MaxTemp          float64\n",
    "        Rainfall         float64\n",
    "        Evaporation      float64\n",
    "        Sunshine         float64\n",
    "        WindGustDir       object\n",
    "        WindGustSpeed    float64\n",
    "        WindDir9am        object\n",
    "        WindDir3pm        object\n",
    "        WindSpeed9am     float64\n",
    "        WindSpeed3pm     float64\n",
    "        Humidity9am      float64\n",
    "        Humidity3pm      float64\n",
    "        Pressure9am      float64\n",
    "        Pressure3pm      float64\n",
    "        Cloud9am         float64\n",
    "        Cloud3pm         float64\n",
    "        Temp9am          float64\n",
    "        Temp3pm          float64\n",
    "        RainToday         object\n",
    "        RainTomorrow      object\n",
    "\n",
    "Data set columns contains significant null values. Null values in each column are mentioned below\n",
    "        Sunshine         3994\n",
    "        Evaporation      3512\n",
    "        Cloud3pm         2455\n",
    "        Cloud9am         2421\n",
    "        Pressure3pm      1312\n",
    "        Pressure9am      1309\n",
    "        WindGustDir       991\n",
    "        WindGustSpeed     991\n",
    "        WindDir9am        829\n",
    "        WindDir3pm        308\n",
    "        RainToday         240\n",
    "        Rainfall          240\n",
    "        RainTomorrow      239\n",
    "        WindSpeed3pm      107\n",
    "        Humidity3pm       102\n",
    "        Temp3pm            96\n",
    "        WindSpeed9am       76\n",
    "        MinTemp            75\n",
    "        MaxTemp            60\n",
    "        Humidity9am        59\n",
    "        Temp9am            56\n",
    "        Location            0\n",
    "        Date                0\n",
    "\n",
    "TREATMENT OF NULL VALUES\n",
    "\n",
    "        SINCE THE DATA IS TECHNICAL REGARDING THE VALUES OF RAINFALL WE ARE NOT SURE ABOUT THE MISSING VALUES DOES \n",
    "        THE BEST POSSIBLE WAY TO TREAT MISSING VALUES IS TO DROP THEM.\n",
    "\n",
    "        Now we are left with 3790 rows of data after deleting null values.\n",
    "\n",
    "STATISTICAL DESCRIPTION OF DATA SET\n",
    "\n",
    "NUMERICAL COLUMNS\n",
    "        For minimum temperature minimum value is minus 0.7 and maximum value is 28.5.\n",
    "        Data scenes okay for minimum temperature and maximum temperature.\n",
    "        For rainfall colum minimum value is zero that indicates there was some reasons where there was no rainfall at all.\n",
    "        Evaporation sunshine cloud 9:00 a.m. and cloud 3:00 p.m. columns also have zero as minimum values. We need to \n",
    "        keep this in mind and research about skewness if present.\n",
    "\n",
    "CATEGORICAL COLUMNS\n",
    "        For date colum n there are 37 90 total counts from which 1873 values are unique and for 2011 02 07 date has \n",
    "        most frequency.\n",
    "\n",
    "Perth airport location has most occurrences.\n",
    "\n",
    "For went guest direction north direction has stopped frequency.\n",
    "For wind direction at 9:00 a.m. and wind direction at 3:00 p.m. top frequencies are North and South respectively.\n",
    "For column rain today and rain tomorrow no is the most occurring response.\n",
    "\n",
    "CONTINUOUS COLUMNS AND DATA SET\n",
    "        ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine',\n",
    "       'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am',\n",
    "       'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm',\n",
    "       'Temp9am', 'Temp3pm'],\n",
    "\n",
    "CATEGORICAL COLUMNS AND DATA SET\n",
    "        ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm',\n",
    "       'RainToday', 'RainTomorrow']\n",
    "\n",
    "UNIVARIATE ANALYSIS:\n",
    "\n",
    "MOST FREQUENT VALUES IN CATEGORICAL COLUMNS\n",
    "\n",
    "        For Date , most frequent value is:  ModeResult(mode=array(['2011-01-19'], dtype=object), count=array([5])) \n",
    "\n",
    "        For Location , most frequent value is:  ModeResult(mode=array(['Melbourne'], dtype=object), count=array([1622])) \n",
    "\n",
    "        For WindGustDir , most frequent value is:  ModeResult(mode=array(['N'], dtype=object), count=array([713])) \n",
    "\n",
    "        For WindDir9am , most frequent value is:  ModeResult(mode=array(['N'], dtype=object), count=array([906])) \n",
    "\n",
    "        For WindDir3pm , most frequent value is:  ModeResult(mode=array(['SE'], dtype=object), count=array([813])) \n",
    "\n",
    "        For RainToday , most frequent value is:  ModeResult(mode=array(['No'], dtype=object), count=array([6195])) \n",
    "\n",
    "        For RainTomorrow , most frequent value is:  ModeResult(mode=array(['No'], dtype=object), count=array([6195])) \n",
    "\n",
    "UNIQUE VALUES AND THEIR ACCOUNTS IN CATEGORICAL COLUMN\n",
    "\n",
    "        For column Date unique values are:  ['2008-12-01' '2008-12-02' '2008-12-03' ... '2013-06-06' '2013-06-07'\n",
    "         '2013-06-08']\n",
    "        For column Date count of unique values are:  3004 \n",
    "\n",
    "\n",
    "        For column Location unique values are:  ['Albury' 'CoffsHarbour' 'Newcastle' 'Penrith' 'Williamtown' 'Wollongong'\n",
    "         'Melbourne' 'Brisbane' 'Adelaide' 'PerthAirport' 'Darwin' 'Uluru']\n",
    "        For column Location count of unique values are:  12 \n",
    "\n",
    "\n",
    "        For column WindGustDir unique values are:  ['W' 'WNW' 'WSW' 'NE' 'NNW' 'N' 'NNE' 'SW' nan 'ENE' 'SSE' 'S' 'NW' 'SE'\n",
    "         'ESE' 'E' 'SSW']\n",
    "        For column WindGustDir count of unique values are:  16 \n",
    "\n",
    "\n",
    "        For column WindDir9am unique values are:  ['W' 'NNW' 'SE' 'ENE' 'SW' 'SSE' 'S' 'NE' nan 'SSW' 'N' 'WSW' 'ESE' 'E'\n",
    "         'NW' 'WNW' 'NNE']\n",
    "        For column WindDir9am count of unique values are:  16 \n",
    "\n",
    "\n",
    "        For column WindDir3pm unique values are:  ['WNW' 'WSW' 'E' 'NW' 'W' 'SSE' 'ESE' 'ENE' 'NNW' 'SSW' 'SW' 'SE' 'N' 'S'\n",
    "         'NNE' nan 'NE']\n",
    "        For column WindDir3pm count of unique values are:  16 \n",
    "\n",
    "\n",
    "        For column RainToday unique values are:  ['No' 'Yes' nan]\n",
    "        For column RainToday count of unique values are:  2 \n",
    "\n",
    "\n",
    "        For column RainTomorrow unique values are:  ['No' 'Yes' nan]\n",
    "        For column RainTomorrow count of unique values are:  2 \n",
    "\n",
    "VALUE COUNTS OF EACH ENTRY IN CATEGORICAL COLUMNS\n",
    "\n",
    "        For column -- Date -- value counts are: \n",
    "         2011-01-31    5\n",
    "        2011-05-08    5\n",
    "        2011-05-21    5\n",
    "        2011-05-20    5\n",
    "        2011-05-19    5\n",
    "                     ..\n",
    "        2013-01-28    1\n",
    "        2013-01-29    1\n",
    "        2013-01-30    1\n",
    "        2013-01-31    1\n",
    "        2013-06-08    1\n",
    "        Name: Date, Length: 3004, dtype: int64 \n",
    "\n",
    "\n",
    "        For column -- Location -- value counts are: \n",
    "         Melbourne       1622\n",
    "        Williamtown     1230\n",
    "        PerthAirport    1204\n",
    "        Albury           907\n",
    "        Newcastle        822\n",
    "        CoffsHarbour     611\n",
    "        Brisbane         579\n",
    "        Penrith          482\n",
    "        Wollongong       474\n",
    "        Darwin           250\n",
    "        Adelaide         205\n",
    "        Uluru             39\n",
    "        Name: Location, dtype: int64 \n",
    "\n",
    "\n",
    "        For column -- WindGustDir -- value counts are: \n",
    "         N      713\n",
    "        SSE    578\n",
    "        S      577\n",
    "        SW     572\n",
    "        E      557\n",
    "        WNW    531\n",
    "        W      507\n",
    "        WSW    504\n",
    "        SE     484\n",
    "        ENE    415\n",
    "        SSW    396\n",
    "        NW     383\n",
    "        NE     353\n",
    "        NNE    343\n",
    "        ESE    302\n",
    "        NNW    219\n",
    "        Name: WindGustDir, dtype: int64 \n",
    "\n",
    "\n",
    "        For column -- WindDir9am -- value counts are: \n",
    "         N      906\n",
    "        SW     704\n",
    "        NW     625\n",
    "        WSW    543\n",
    "        SE     505\n",
    "        WNW    480\n",
    "        SSW    467\n",
    "        ENE    433\n",
    "        NNE    430\n",
    "        W      414\n",
    "        NE     409\n",
    "        S      402\n",
    "        E      380\n",
    "        SSE    365\n",
    "        NNW    280\n",
    "        ESE    253\n",
    "        Name: WindDir9am, dtype: int64 \n",
    "\n",
    "\n",
    "        For column -- WindDir3pm -- value counts are: \n",
    "         SE     813\n",
    "        S      742\n",
    "        SSE    623\n",
    "        WSW    580\n",
    "        NE     544\n",
    "        N      524\n",
    "        SW     494\n",
    "        WNW    487\n",
    "        NW     468\n",
    "        W      462\n",
    "        ESE    462\n",
    "        E      460\n",
    "        ENE    417\n",
    "        SSW    370\n",
    "        NNE    365\n",
    "        NNW    306\n",
    "        Name: WindDir3pm, dtype: int64 \n",
    "\n",
    "\n",
    "        For column -- RainToday -- value counts are: \n",
    "         No     6195\n",
    "        Yes    1990\n",
    "        Name: RainToday, dtype: int64 \n",
    "\n",
    "\n",
    "        For column -- RainTomorrow -- value counts are: \n",
    "         No     6195\n",
    "        Yes    1991\n",
    "        Name: RainTomorrow, dtype: int64 \n",
    "\n",
    "\n",
    "# Univariate analysis:\n",
    "\n",
    "        COUNT PLOT ANALYSIS SUMMARY\n",
    "        For different locations contributing to rainfall data, Melbourne and perth airport location contributed to maximum \n",
    "        number of rainfall data and William town and Darwin contributed the least.\n",
    "\n",
    "        For went girls direction maximum count is for East Southwest and north direction respectively.\n",
    "\n",
    "        For when direction at 9:00 a.m. maximum count is for north and Southwest direction respectively.\n",
    "\n",
    "        For wind direction at 3:00 p.m. south direction has highest number of counts.\n",
    "\n",
    "        For most Number of days there was no rainfall today and tomorrow.\n",
    "\n",
    "BY VARIATE ANALYSIS\n",
    "        Cat plot analysis summary:\n",
    "        For cloud 9:00 a.m. and cloud 3:00 p.m. maximum possibility of rainfall is when the reading is 7 at cloud 9:00 a.m. colum.\n",
    "\n",
    "BOX PLOT SUMMARY\n",
    "\n",
    "        Fortime 3:00 p.m. colum and temp 9:00 p.m. colum for Melbourne and Perth airport location\n",
    "        Possibility of rainfall tomorrow is high. Melbourne and perth airport location data contains lot of outliers as well.\n",
    "        Cloud 9:00 p.m. data indicates for cough herber and Perth airport possibility of rainfall tomorrow is high. Here also \n",
    "        Melbourne data set contains out liars.\n",
    "        Wind speed 9:00 a.m. box plot with location and rain tomorrow indicates that Melbourne Brisbane data have lots of outliers. \n",
    "        For low Sunshine values typically for all locations possibility of rain tomorrow is high.\n",
    "        Possibility of rain tomorrow is no for high evaporation values for williamtown location.\n",
    "        For Max temperature values ranging from 15 to 30 possibility of rainfall is high for Melbourne and pers airport \n",
    "        locations where and Perth airport contains lot of outliers.\n",
    "        Possibility of rainfall at coffs harbour and Brisbane is high and max temperature range is between 20 to 25.\n",
    "        Proportionately as for rainfall tomorrow data possibility of rainfall today is quite high for Melbourne and Perth \n",
    "        airport locations.\n",
    "        For evaporation values renging from 5 to 15 possibility of rain today is quite high for William town.\n",
    "        For Sunshine values ranging from 2 to 8 possibility of rainfall is quite high for nearly all locations.\n",
    "        For humidity 9:00 a.m. values above 70 high possibility of rainfall can be seen for nearly all locations.\n",
    "        For darvin location possibility of rainfall today is hi for low pressure 9M values as compared to other locations.\n",
    "\n",
    "STRIP PLOT SUMMARY\n",
    "        Rainfall today and tomorrow can be expected considerably for locations Melbourne Perth airport and coffs harbour.\n",
    "        Very less rainfall can be expected for William town and Brisbane and Darwin location.\n",
    "\n",
    "ANALYSING RELATIONSHIPS USING LM PLOT\n",
    "\n",
    "        Rain today has a positive relationship with min temp and humidity 9:00 a.m. , min temp and humidity 3:00 p.m. \n",
    "        cloud 9:00 a.m. and mintemp and temp 9:00 a.m.\n",
    "        Pressure and cloud columns with evaporation rainfall show neutral relationship.\n",
    "        Sunshine feature has negative relationship with the rain today and rain tomorrow nearly for all other features as well.\n",
    "\n",
    "MULTIVARIATE ANALYSIS USING PAIR PLOT\n",
    "\n",
    "CHECKING CORRELATION BETWEEN FEATURES AND TARGET VARIABLE\n",
    "\n",
    "        Sunshine evaporation and max temperature have negative correlation with rainfall column.\n",
    "\n",
    "        Humidity columns and cloud columns have high positive correlation with rainfall.\n",
    "\n",
    "ANALYSING MULTI COLLINEARITY PROBLEM\n",
    "        Wind speed 9:00 a.m. and wind speed 3:00 p.m. and wind gust speed are are highly correlated to each other. \n",
    "        Temperature columns are also highly related to each other and does the value of one column can be used to protect \n",
    "        the value of other colum. That's we can conclude that multi collinearity problem exist.\n",
    "\n",
    "USING VARIANCE INFLATION FACTOR\n",
    "        Min temperature Max temperature evaporation Sunshine wind speed columns humidity and pressure columns and early \n",
    "        all of other columns have high variance in fashion factor values and does we need to treat them.\n",
    "\n",
    "FURTHER STEPS PERFORMED\n",
    "        Selection of features and target column\n",
    "        Encoding categorical columns\n",
    "        Normalising data using power transform\n",
    "        Feature selection using principle component analysis\n",
    "        Splitting training and testing data\n",
    "        Model instantiation\n",
    "        Model validation\n",
    "        Selecting best model and hyperparameter boosting\n",
    "        Result:\n",
    "            Training accuracy:  96.65485157288435\n",
    "            Testing accuracy:  84.97913769123782\n",
    "            Confusion matrix: \n",
    "             [[521  27]\n",
    "             [ 81  90]]\n",
    "            classification report:                precision    recall  f1-score   support\n",
    "\n",
    "                       0       0.87      0.95      0.91       548\n",
    "                       1       0.77      0.53      0.62       171\n",
    "\n",
    "                accuracy                           0.85       719\n",
    "               macro avg       0.82      0.74      0.77       719\n",
    "            weighted avg       0.84      0.85      0.84       719\n",
    "        Saving the model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_data = df.select_dtypes(include=['int64','float64'])\n",
    "\n",
    "cat_data= df.select_dtypes(include=['object'])\n",
    "\n",
    "cont_columns = cont_data.columns\n",
    "\n",
    "cat_columns = cat_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88058cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for i in cat_columns:\n",
    "    print('For',i,', most frequent value is: ',stats.mode(df[i]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390bb20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column',i,'unique values are: ',df[i].unique())\n",
    "    print('For column',i,'count of unique values are: ',df[i].nunique(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1788528",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_columns:\n",
    "    print('For column --',i,'-- value counts are: \\n',df[i].value_counts(),'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis:\n",
    "\n",
    "for i in cat_columns:\n",
    "    f= plt.figure(figsize=(12,5))\n",
    "    ax = sns.countplot(x=df[i],data=df)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2901404",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    f= plt.figure(figsize=(20,20))\n",
    "    ax = sns.catplot(x=i, kind=\"count\",hue = 'RainTomorrow', data=df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f95f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Temp3pm', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eac211",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Temp9am', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Cloud3pm', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Cloud9am', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f4e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Pressure9am', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab434d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Pressure3pm', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c73c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Humidity9am', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e886c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='WindSpeed3pm', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fdd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='WindSpeed9am', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17014288",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='WindGustSpeed', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e78bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Sunshine', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14efb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Evaporation', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='Rainfall', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='MaxTemp', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a10b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x ='Location', y ='MinTemp', data = df, hue ='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='Location', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c04b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc541b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='WindGustDir', y =i, data = df, hue ='RainTomorrow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3434bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='WindDir9am', y =i, data = df, hue ='RainTomorrow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='WindDir3pm', y =i, data = df, hue ='RainTomorrow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='WindGustDir', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='WindDir9am', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.boxplot(x ='WindDir3pm', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af794a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7947c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.violinplot(x ='WindGustDir', y =i, data = df, hue ='RainTomorrow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f762c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.violinplot(x ='WindDir9am', y =i, data = df, hue ='RainTomorrow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.violinplot(x ='WindDir3pm', y =i, data = df, hue ='RainTomorrow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.violinplot(x ='WindGustDir', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d834a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.violinplot(x ='WindDir9am', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9118e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cont_columns:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    sns.violinplot(x ='WindDir3pm', y =i, data = df, hue ='RainToday')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lineplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae0b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ebde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "    for j in cont_columns:\n",
    "        plt.figure(figsize=(15,10))\n",
    "        sns.stripplot(x = j, y =i, data = df, hue = 'RainToday')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f237871",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "    for j in cont_columns:\n",
    "        plt.figure(figsize=(15,10))\n",
    "        sns.stripplot(x = j, y =i, data = df, hue = 'RainTomorrow')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e70ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6637d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "    for j in cont_columns:\n",
    "        plt.figure(figsize=(15,10))\n",
    "        sns.lineplot(x = j, y =i, data = df, hue = 'RainTomorrow')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']:\n",
    "    for j in cont_columns:\n",
    "        plt.figure(figsize=(15,10))\n",
    "        sns.lineplot(x = j, y =i, data = df, hue = 'RainToday')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26122cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Furthur analysing relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a96706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine','WindGustSpeed', 'WindSpeed9am']:\n",
    "    for j in ['WindSpeed3pm', 'Humidity9am','Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm','Temp9am', 'Temp3pm']:\n",
    "        plt.figure(figsize=(15,10))\n",
    "        sns.lmplot(x = j,y=i, data = df, hue = 'RainToday')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370505a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine','WindGustSpeed', 'WindSpeed9am']:\n",
    "    for j in ['WindSpeed3pm', 'Humidity9am','Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm','Temp9am', 'Temp3pm']:\n",
    "        plt.figure(figsize=(15,10))\n",
    "        sns.lmplot(x = j,y=i, data = df, hue = 'RainTomorrow')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923c74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5213d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "3790-3592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79154d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "198/3790*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699433f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue='RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2195fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features and label:\n",
    "\n",
    "# Replacing attrition column values:\n",
    "\n",
    "df.drop(columns = 'Rainfall',axis = 1).corrwith(df.Rainfall).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking relationship between independent and dependent variable:\n",
    "\n",
    "df_corr = df.corr().abs()\n",
    "plt.figure(figsize=(18,14))\n",
    "sns.heatmap(df_corr,annot=True,annot_kws={'size':10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9dd23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif['vif'] = [variance_inflation_factor(df[cont_columns],i) for i in range(df[cont_columns].shape[1])]\n",
    "vif['features'] = df[cont_columns].columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab29358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Z Statistics to check and remove any more outliers:\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "z_score = zscore(df[cont_columns])\n",
    "\n",
    "abs_z_score = np.abs(z_score)\n",
    "\n",
    "filtering_entry = (abs_z_score < 3).all(axis=1) # values lying in 3 times std will be removed\n",
    "\n",
    "df = df[filtering_entry]\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533dddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y1 = df['Rainfall']\n",
    "X_pre = df.drop(['Rainfall'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dums = pd.get_dummies(X_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1330e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dums.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a574ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans1 = pt.fit_transform(X_dums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca1 = PCA()\n",
    "pca1.fit_transform(X_trans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca1.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae71985",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components=1750)\n",
    "new_pcomp1 = pca1.fit_transform(X_trans1)\n",
    "princi_comp1 = pd.DataFrame(new_pcomp1)\n",
    "princi_comp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Spliting data\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "# Importing metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "# Removing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting our data to training data and testing data\n",
    "# x_train,x_test,y_train,y_test\n",
    "\n",
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(princi_comp1,y1,test_size=0.20,random_state=1)\n",
    "\n",
    "# Here we are keeping training data as our scalled data and testing data as our label or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e633cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOdel instantiating and training\n",
    "\n",
    "rm = LinearRegression()\n",
    "rm.fit(x_train1,y_train1) \n",
    "# here we will pass training data\n",
    "\n",
    "y_pred = rm.predict(x_test1)\n",
    "\n",
    "print('Training score', rm.score(x_train1,y_train1))\n",
    "\n",
    "print(\" Testing Score: \", rm.score(x_test1, y_test1))\n",
    "\n",
    "plt.scatter(y_test1,y_pred)\n",
    "plt.xlabel('Actual Charges')\n",
    "plt.ylabel('Predicted Charges')\n",
    "plt.title('Actual vs Model Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso,RidgeCV,LassoCV\n",
    "\n",
    "lassocv = LassoCV(alphas = None , max_iter = 100, normalize = True)\n",
    "lassocv.fit(x_train1,y_train1)\n",
    "\n",
    "# Best alpha parameter\n",
    "alpha = lassocv.alpha_ # Best alpha rate\n",
    "print(alpha)\n",
    "\n",
    "# Now since we have the best parameter, lasso regression will be used:\n",
    "lasso_reg = Lasso(alpha)\n",
    "lasso_reg.fit(x_train1,y_train1)\n",
    "# i.e. when model is training it will learn at this speed 6...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73378f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg.score(x_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89b608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Method:\n",
    "\n",
    "ridgecv = RidgeCV(alphas = np.arange(0.001,0.1,0.01),normalize = True)\n",
    "ridgecv.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgecv.alpha_ # Best alpha rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a15cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha = ridgecv.alpha_)\n",
    "ridge_model.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82875d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.score(x_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab508493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model performance\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test1, y_pred))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test1, y_pred))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test1, y_pred, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test1, y_pred), \"\\n\")\n",
    "print(\"Score: \", rm.score(x_test1, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d1379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using decision tree:\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "model.fit(x_train1, y_train1)\n",
    "\n",
    "y_preddt = model.predict(x_test1)\n",
    "\n",
    "r2_score(y_test1,y_preddt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0bff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest:\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor_rf = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "regressor_rf.fit(x_train1, y_train1)\n",
    "\n",
    "lr_normal_rf = regressor_rf.score(x_train1, y_train1)\n",
    "\n",
    "lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada17818",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predrf = regressor_rf.predict(x_test1)\n",
    "\n",
    "lr_normal_rf_test = regressor_rf.score(x_test1, y_test1)\n",
    "\n",
    "lr_normal_rf_test\n",
    "\n",
    "mse_lr_normal_rf  = mean_absolute_error(y_test1, y_predrf)\n",
    "\n",
    "mse_lr_normal_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test1, y_predrf))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test1, y_predrf))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test1, y_predrf, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test1, y_predrf), \"\\n\")\n",
    "print(\"Score: \", regressor_rf.score(x_test1, y_predrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support vector regressor:\n",
    "\n",
    "# Fit the model over the training data\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "svr.fit(x_train1, y_train1)\n",
    "\n",
    "y_predsvr = svr.predict(x_test1)\n",
    "\n",
    "r2_score(y_test1,y_predsvr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4e919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost:\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor()\n",
    "xgb_clf.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d348e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using XGBoost:\n",
    "\n",
    "xgb_clf = xgb.XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
    "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
    "             early_stopping_rounds=None, enable_categorical=False,\n",
    "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
    "             importance_type=None, interaction_constraints='',\n",
    "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
    "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1\n",
    "             ,monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
    "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
    "             reg_lambda=1)\n",
    "\n",
    "xgb_clf.fit(x_train1,y_train1)\n",
    "\n",
    "y_predx = xgb_clf.predict(x_test1)\n",
    "\n",
    "r2_score(y_test1,y_predx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for xgboost model\n",
    "\n",
    "params = {\"learning_rate\"    : [0.05, 0.10] ,\n",
    "         \"max_depth\"        : [ 3, 5, 8, 12]}\n",
    "\n",
    "grd = GridSearchCV(xgb_clf,param_grid=params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9632914",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_boosted = grd.fit(x_train1,y_train1)\n",
    "\n",
    "y_predxx = xgb_boosted.predict(x_test1)\n",
    "\n",
    "r2_score(y_test1,y_predxx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "ada.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predada = ada.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd79c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test1,y_predada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839a4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameter tuning using Randomised Search CV :\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {'n_estimators':[47,50,60,70],'learning_rate':[0.25,0.3,0.4]}\n",
    "\n",
    "rnd = RandomizedSearchCV(ada,param_distributions=params)\n",
    "\n",
    "rnd.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boosted = AdaBoostRegressor(learning_rate=0.25)\n",
    "\n",
    "ada_boosted.fit(x_train1,y_train1)\n",
    "\n",
    "yb_pred = ada_boosted.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002cdf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: MAE , MSE , RMSE\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "\n",
    "print(\"MAE: \", metrics.mean_absolute_error(y_test1, yb_pred))\n",
    "print(\"MSE: \", metrics.mean_squared_error(y_test1, yb_pred))\n",
    "print(\"RMSE: \", metrics.mean_squared_error(y_test1, yb_pred, squared=False))\n",
    "print(\"R2: \", metrics.r2_score(y_test1, yb_pred), \"\\n\")\n",
    "print(\"Score: \", ada_boosted.score(x_test1, yb_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f09b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe1 = Pipeline([('pt',PowerTransformer()),('pca',PCA(n_components=1750)),('base_model1',xgb.XGBRegressor())])\n",
    "\n",
    "pipe1.fit(x_train1,y_train1)\n",
    "\n",
    "y_pred1 = pipe1.predict(x_test1)\n",
    "\n",
    "metrics.r2_score(y_test1, y_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving regression model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model1 = pickle.dumps(pipe1) \n",
    "pipe_pickle1 = pickle.loads(saved_model1)\n",
    "pipe_pickle1.predict(X_test) # predicting testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbdd49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using label encoder to encode dependent variable column:\n",
    "\n",
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "df['RainTomorrow']= label_encoder.fit_transform(df['RainTomorrow'])\n",
    "  \n",
    "df['RainTomorrow'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5aa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features and label:\n",
    "\n",
    "# Replacing attrition column values:\n",
    "\n",
    "df.drop(columns = 'RainTomorrow',axis = 1).corrwith(df.RainTomorrow).plot(kind='bar',grid=True,figsize=(10,7),title='corelation between features and labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f175479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using label encoder to encode dependent variable column:\n",
    "\n",
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "  \n",
    "# label_encoder object knows how to understand word labels.\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "# Encode labels in column 'species'.\n",
    "df['RainTomorrow']= label_encoder.fit_transform(df['RainTomorrow'])\n",
    "  \n",
    "df['RainTomorrow'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into features and label:\n",
    "\n",
    "y = df['RainTomorrow']\n",
    "X = df.drop(['RainTomorrow'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ef163",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1629e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47da9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aaa128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "pt = PowerTransformer()\n",
    "\n",
    "X_trans = pt.fit_transform(X_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2698d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Using PCA i.e. Principal Component Analysis that is a diamensionallity reduction technique:\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit_transform(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b27033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Scree Plot to identify best components:\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Covered')\n",
    "plt.title('PCA')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91253233",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1750)\n",
    "new_pcomp = pca.fit_transform(X_trans)\n",
    "princi_comp = pd.DataFrame(new_pcomp)\n",
    "princi_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ed84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "princi_comp.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(princi_comp, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f80fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(y_train_res)\n",
    "\n",
    "un, co = np.unique(arr,return_counts=True)\n",
    "\n",
    "dict(zip(un,co))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86664025",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06290de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression:\n",
    "\n",
    "log_reg = LogisticRegression(random_state=1)\n",
    "\n",
    "log_reg.fit(X_train_res,y_train_res) \n",
    "\n",
    "pred_train = log_reg.predict(X_train_res)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "\n",
    "clr = classification_report(y_test,y_pred)\n",
    "\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best result for Decision Tree Classifier:\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=1)\n",
    "dtc.fit(X_train_res,y_train_res) \n",
    "pred_train_dtc = dtc.predict(X_train_res)\n",
    "y_pred = dtc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_dtc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ed2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forrest classifier model:\n",
    "\n",
    "rfc_f = RandomForestClassifier()\n",
    "rfc_f.fit(X_train_res,y_train_res) \n",
    "pred_train_rfc_f = rfc_f.predict(X_train_res)\n",
    "y_pred = rfc_f.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_rfc_f)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using best parameters for improved score:\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train_res,y_train_res)\n",
    "\n",
    "pred_train_svc = svc.predict(X_train_res)\n",
    "y_pred = svc.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_svc)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classifier:\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_res,y_train_res) \n",
    "pred_train_knn = knn.predict(X_train_res)\n",
    "y_pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_knn)*100)\n",
    "print('Testing accuracy: ', acc*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2543bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GBC\n",
    "\n",
    "gbdt_clf = GradientBoostingClassifier(random_state=3)\n",
    "gbdt_clf.fit(X_train_res,y_train_res) \n",
    "pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "y_pred = gbdt_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADA model:\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_boosted = AdaBoostClassifier()\n",
    "ada_boosted.fit(X_train_res,y_train_res)\n",
    "yb_pred = ada_boosted.predict(X_test)\n",
    "pred_train_ada = ada_boosted.predict(X_train_res)\n",
    "y_pred = ada_boosted.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_ada)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1602f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(X_train_res, y_train_res)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ce501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets plot ROC AUC curve to choose best model:\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad81df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check ROC AUC Curve for fitted models on training data: (True +ive Rate/False +ive Rate)\n",
    "\n",
    "disp = plot_roc_curve(dtc,X_train_res,y_train_res)\n",
    "\n",
    "plot_roc_curve(knn,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(log_reg,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(svc,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(rfc_f,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(ada_boosted,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(gbdt_clf,X_train_res,y_train_res,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# This result is on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f5c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check ROC AUC Curve for fitted models on testing data: (True +ive Rate/False +ive Rate)\n",
    "\n",
    "disp = plot_roc_curve(dtc,X_test,y_test)\n",
    "\n",
    "plot_roc_curve(knn,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(log_reg,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(svc,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(rfc_f,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(ada_boosted,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plot_roc_curve(gbdt_clf,X_test,y_test,ax=disp.ax_)\n",
    "\n",
    "plt.legend(prop={'size':10},loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# This result is on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e287d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter tuning GBC classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5651e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth':range(4,8),\n",
    "          'min_samples_split':range(2,8,2),\n",
    "          'learning_rate':np.arange(0.1,0.3)}\n",
    "\n",
    "gridsearch = GridSearchCV(estimator=gbdt_clf,param_grid=param_grid)\n",
    "\n",
    "gridsearch.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f28762",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating gradient boosting classifier:\n",
    "\n",
    "gbdt_clf_f = GradientBoostingClassifier(learning_rate=0.1, max_depth=7, min_samples_split=2)\n",
    "\n",
    "# Training the model\n",
    "gbdt_clf_f.fit(X_train_res,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a781a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdt_clf = GradientBoostingClassifier(random_state=3)\n",
    "gbdt_clf.fit(X_train_res,y_train_res) \n",
    "pred_train_gbdt_clf = gbdt_clf.predict(X_train_res)\n",
    "y_pred = gbdt_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print('Training accuracy: ', accuracy_score(y_train_res,pred_train_gbdt_clf)*100)\n",
    "print('Testing accuracy: ', acc*100)\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "print('Confusion matrix: \\n',confusion_mat)\n",
    "clr = classification_report(y_test,y_pred)\n",
    "print('classification report: ' ,clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72966c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b882de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pipeline:\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe1 = Pipeline([('pt',PowerTransformer()),\n",
    "                  ('pca',PCA(n_components=17000)),('base_model1',GradientBoostingClassifier(random_state=3))])\n",
    "\n",
    "pipe1.fit(X_train_res,y_train_res)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)\n",
    "\n",
    "# Saving regression model to pickle string\n",
    "\n",
    "import pickle \n",
    "saved_model1 = pickle.dumps(pipe1) \n",
    "pipe_pickle1 = pickle.loads(saved_model1)\n",
    "pipe_pickle1.predict(X_test) # predicting testing data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
