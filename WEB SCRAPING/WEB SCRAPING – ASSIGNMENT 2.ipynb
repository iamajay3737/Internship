{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292124df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\classic\\anaconda3\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\classic\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\classic\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dbc990",
   "metadata": {},
   "source": [
    "# 1. All the questions must be done in a single Jupyter notebook.\n",
    "# 2. There should be proper comments incode.\n",
    "#  Q1) : Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "# have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "# jobs data.\n",
    "# This task will be done in following steps:\n",
    "            1. First get the webpage https://www.naukri.com/\n",
    "            2.  Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "                  location” field.\n",
    "            3. Then click the searchbutton.\n",
    "            4. Then scrape the data for the first 10 jobs results you get.\n",
    "            5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322cc9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae63357",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\CLASSIC\\OneDrive\\Documents\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8ae8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef3c9f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd22a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div[1]/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb931db",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4fc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ab2a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5bdd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb9c9a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bayer</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Target</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urgent Opening For Data Analyst | MNC | Bangal...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yellow Box Hr Services</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Urgent Hiring For Data Analyst For MNC - Banga...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Yellow Box Hr Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Volvo Financial Services</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Globals Ites</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Cynosure Corporate Solutions</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistics Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Reshamandi</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                       Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Urgent Opening For Data Analyst | MNC | Bangal...   \n",
       "3  Urgent Hiring For Data Analyst For MNC - Banga...   \n",
       "4                                       Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                                       Data Analyst   \n",
       "8                                       Data Analyst   \n",
       "9                             Logistics Data Analyst   \n",
       "\n",
       "                                            location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                   Company_name Experience  \n",
       "0                         Bayer    2-5 Yrs  \n",
       "1                        Target    2-4 Yrs  \n",
       "2        Yellow Box Hr Services    4-9 Yrs  \n",
       "3        Yellow Box Hr Services    3-8 Yrs  \n",
       "4      Volvo Financial Services    2-4 Yrs  \n",
       "5                           IBM    2-4 Yrs  \n",
       "6                  Globals Ites    2-3 Yrs  \n",
       "7                        Varite    4-5 Yrs  \n",
       "8  Cynosure Corporate Solutions    2-7 Yrs  \n",
       "9                    Reshamandi    1-3 Yrs  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d26ffca",
   "metadata": {},
   "source": [
    "# Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "# have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "# This task will be done in following steps:\n",
    "        1. First get the webpage https://www.naukri.com/\n",
    "        2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "           location” field.\n",
    "        3. Then click the searchbutton.\n",
    "        4. Then scrape the data for the first 10 jobs results youget.\n",
    "        5. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37389c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\CLASSIC\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae5878d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4ab490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55abfe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7394cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea7696c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//span[@class=\"starRating fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf012096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d78c1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Professional - IBM SPSS Statistic...</td>\n",
       "      <td>Noida, Mumbai, Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior data scientist</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Manager - Innovations Hub - Machine Learning</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Staff Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>4.2</td>\n",
       "      <td>10-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2  Data Science Professional - IBM SPSS Statistic...   \n",
       "3                              Senior data scientist   \n",
       "4                                 Data Scientist_NLP   \n",
       "5                                     Data Scientist   \n",
       "6       Manager - Innovations Hub - Machine Learning   \n",
       "7                                  Data Scientist II   \n",
       "8                    Machine Learning (AI) Architect   \n",
       "9                               Staff Data Scientist   \n",
       "\n",
       "                                            location Company_name Experience  \n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...          4.1    2-4 Yrs  \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...          4.1    6-8 Yrs  \n",
       "2  Noida, Mumbai, Pune, Chennai, Bangalore/Bengaluru          3.7    5-8 Yrs  \n",
       "3  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...          4.1    4-8 Yrs  \n",
       "4  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...          4.1   5-11 Yrs  \n",
       "5  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...          4.1    3-7 Yrs  \n",
       "6  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...          3.7    7-9 Yrs  \n",
       "7                                Bangalore/Bengaluru          4.2    5-7 Yrs  \n",
       "8  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...          4.1   5-12 Yrs  \n",
       "9                        Mumbai, Bangalore/Bengaluru          4.2  10-12 Yrs  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8452e",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "# You have to use the location and salary filter.\n",
    "# You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "# You have to scrape the job-title, job-location, company name, experience required.\n",
    "# The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "# The task will be done as shown in the below steps:\n",
    "        1. first get thewebpage https://www.naukri.com/\n",
    "        2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "        3. Then click the searchbutton.\n",
    "        4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "        5. Then scrape the data for the first 10 jobs results youget.\n",
    "        6. Finally create a dataframe of the scraped data.\n",
    "# Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb8a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\CLASSIC\\Downloads\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54d384a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcacdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a07b4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Delhi / NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "471f9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c5c7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "job_salary=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "523a5e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Job title from the given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "# scraping Job Location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "# scraping Company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# scraping Job Experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "# scraping Job Salary from the given page\n",
    "salary_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft \"]')\n",
    "for i in salary_tags[0:10]:\n",
    "    salary=i.text\n",
    "    job_salary.append(salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaae0fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required),len(job_salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "119a4424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Professional - IBM SPSS Statistic...</td>\n",
       "      <td>Noida, Mumbai, Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior data scientist</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lotus Interworks - Data Scientist</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Lotus Interworks Inc</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr Data Scientist (ML / CV / NLP)</td>\n",
       "      <td>Mumbai, New Delhi, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>AVE-Promagne Business Solutions</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - R/Python</td>\n",
       "      <td>Temp. WFH - Delhi / NCR, Kolkata, Mumbai, Visa...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Associate Director</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>TRH Consultancy Services</td>\n",
       "      <td>10-20 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>7-11 Lacs PA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Science Professional - IBM SPSS Statistic...   \n",
       "1                              Senior data scientist   \n",
       "2                                 Data Scientist_NLP   \n",
       "3                                     Data Scientist   \n",
       "4                    Machine Learning (AI) Architect   \n",
       "5                  Lotus Interworks - Data Scientist   \n",
       "6                  Sr Data Scientist (ML / CV / NLP)   \n",
       "7                          Data Scientist - R/Python   \n",
       "8                    Data Science Associate Director   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                            location  \\\n",
       "0  Noida, Mumbai, Pune, Chennai, Bangalore/Bengaluru   \n",
       "1  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...   \n",
       "2  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...   \n",
       "3  Mumbai, Pune, Chennai, Gurgaon/Gurugram, Banga...   \n",
       "4  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "5  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "6       Mumbai, New Delhi, Pune, Bangalore/Bengaluru   \n",
       "7  Temp. WFH - Delhi / NCR, Kolkata, Mumbai, Visa...   \n",
       "8  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "9  Hyderabad/Secunderabad, Gurgaon/Gurugram, Bang...   \n",
       "\n",
       "                      Company_name Experience         Salary  \n",
       "0            Hexaware Technologies    5-8 Yrs  Not disclosed  \n",
       "1                Fractal Analytics    4-8 Yrs  Not disclosed  \n",
       "2                Fractal Analytics   5-11 Yrs  Not disclosed  \n",
       "3                Fractal Analytics    3-7 Yrs  Not disclosed  \n",
       "4                       Persistent   5-12 Yrs  Not disclosed  \n",
       "5             Lotus Interworks Inc    1-5 Yrs  Not disclosed  \n",
       "6  AVE-Promagne Business Solutions    4-8 Yrs  Not disclosed  \n",
       "7                   Okda Solutions    4-7 Yrs  Not disclosed  \n",
       "8         TRH Consultancy Services  10-20 Yrs  Not disclosed  \n",
       "9                    Tech Mahindra   5-10 Yrs   7-11 Lacs PA  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'location':job_location,'Company_name':company_name,'Experience':experience_required,'Salary':job_salary})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15732d89",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "            1. Brand\n",
    "            2. ProductDescription\n",
    "            3. Price\n",
    "# The attributes which you have to scrape is ticked marked in the below image.\n",
    "# To scrape the data you have to go through following steps:\n",
    "            1. Go to Flipkart webpage by url :https://www.flipkart.com/     \n",
    "            2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "               click the search icon\n",
    "            3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "               required data asusual.\n",
    "            4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "               click on it.\n",
    "            5. Now scrape data from this page asusual\n",
    "            6. Repeat this until you get data for 100sunglasses.\n",
    "# Note: That all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "230a6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"http://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88cb0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('sunglasses')\n",
    "\n",
    "pop_up=driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "pop_up.click()\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd8fd4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract all web elements having 100 Sunglass Brand\n",
    "brands=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in title_tag:\n",
    "        brands.append(i.text.split(\",\"))\n",
    "brands=brands[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "432ca475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract all web elements having 100 Sunglass Product Discription\n",
    "prod_des=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in title_tag:\n",
    "        prod_des.append(i.text.split(\",\"))\n",
    "prod_des=prod_des[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aea26f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets extract all web elements having 100 Sunglass Price\n",
    "price=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in title_tag:\n",
    "        price.append(i.text.split(\" \"))\n",
    "price=price[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61ff9b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunglass Brands</th>\n",
       "      <th>Production Descripion</th>\n",
       "      <th>Sunglass Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ROZZETTA CRAFT]</td>\n",
       "      <td>[Polarized,  UV Protection Aviator Sunglasses ...</td>\n",
       "      <td>[₹492]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Velocity Eyewear]</td>\n",
       "      <td>[UV Protection Sports Sunglasses (Free Size)]</td>\n",
       "      <td>[₹1,549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[SRPM]</td>\n",
       "      <td>[UV Protection Wayfarer Sunglasses (50)]</td>\n",
       "      <td>[₹149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Elligator]</td>\n",
       "      <td>[UV Protection Cat-eye,  Retro Square,  Oval, ...</td>\n",
       "      <td>[₹149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Elligator]</td>\n",
       "      <td>[UV Protection Aviator,  Wayfarer Sunglasses (...</td>\n",
       "      <td>[₹149]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[Velocity Eyewear]</td>\n",
       "      <td>[UV Protection Round Sunglasses (53)]</td>\n",
       "      <td>[₹1,499]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[Fastrack]</td>\n",
       "      <td>[UV Protection Sports Sunglasses (62)]</td>\n",
       "      <td>[₹749]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[Fastrack]</td>\n",
       "      <td>[UV Protection Wayfarer Sunglasses (53)]</td>\n",
       "      <td>[₹579]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[Fastrack]</td>\n",
       "      <td>[UV Protection Wayfarer Sunglasses (56)]</td>\n",
       "      <td>[₹639]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[IRUS]</td>\n",
       "      <td>[UV Protection Oval Sunglasses (54)]</td>\n",
       "      <td>[₹719]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sunglass Brands                              Production Descripion  \\\n",
       "0     [ROZZETTA CRAFT]  [Polarized,  UV Protection Aviator Sunglasses ...   \n",
       "1   [Velocity Eyewear]      [UV Protection Sports Sunglasses (Free Size)]   \n",
       "2               [SRPM]           [UV Protection Wayfarer Sunglasses (50)]   \n",
       "3          [Elligator]  [UV Protection Cat-eye,  Retro Square,  Oval, ...   \n",
       "4          [Elligator]  [UV Protection Aviator,  Wayfarer Sunglasses (...   \n",
       "..                 ...                                                ...   \n",
       "95  [Velocity Eyewear]              [UV Protection Round Sunglasses (53)]   \n",
       "96          [Fastrack]             [UV Protection Sports Sunglasses (62)]   \n",
       "97          [Fastrack]           [UV Protection Wayfarer Sunglasses (53)]   \n",
       "98          [Fastrack]           [UV Protection Wayfarer Sunglasses (56)]   \n",
       "99              [IRUS]               [UV Protection Oval Sunglasses (54)]   \n",
       "\n",
       "   Sunglass Price  \n",
       "0          [₹492]  \n",
       "1        [₹1,549]  \n",
       "2          [₹149]  \n",
       "3          [₹149]  \n",
       "4          [₹149]  \n",
       "..            ...  \n",
       "95       [₹1,499]  \n",
       "96         [₹749]  \n",
       "97         [₹579]  \n",
       "98         [₹639]  \n",
       "99         [₹719]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets make datafram\n",
    "import pandas as pd\n",
    "sunglass=pd.DataFrame({\"Sunglass Brands\":brands,\"Production Descripion\":prod_des,\"Sunglass Price\":price})\n",
    "sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d21ab",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "# https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market \n",
    "# place=FLIPKART\n",
    "# As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "               1. Rating\n",
    "               2. Review summary\n",
    "               3. Full review\n",
    "               4. You have to scrape this data for first 100reviews.\n",
    "# Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "050b5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb/p/itm4e5041ba101fd\" # Here i am assigning the link in url name variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87ff74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "rating_review=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div\")\n",
    "rating_review.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ab4ebaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating = []\n",
    "start=0\n",
    "end=11\n",
    "for page in range(start,end,1):\n",
    "    rating = driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    for i in rating:\n",
    "        Rating.append(i.text)\n",
    "    \n",
    "    time.sleep(3)\n",
    "Rating=Rating[0:100]\n",
    "len(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e6f3705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review = []\n",
    "start=0\n",
    "end=11\n",
    "for page in range(end,start,-1):\n",
    "    review = driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "    for i in review:\n",
    "        Review.append(i.text)\n",
    "    \n",
    "    time.sleep(3)\n",
    "Review=Review[0:100]\n",
    "len(Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ae8cdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_review = []\n",
    "start=0\n",
    "end=11\n",
    "for page in range(start,end,1):\n",
    "    review = driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']\")\n",
    "    for i in review:\n",
    "        Full_review.append(i.text)\n",
    "    \n",
    "    \n",
    "Full_review=Full_review[0:100]\n",
    "len(Full_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3acd2b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I Phone 11 Rating</th>\n",
       "      <th>I Phone Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money\\n5 star rating\\nExcellent came...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   I Phone 11 Rating       I Phone Review  \\\n",
       "0                  5       Simply awesome   \n",
       "1                  5     Perfect product!   \n",
       "2                  5  Best in the market!   \n",
       "3                  4      Value-for-money   \n",
       "4                  5   Highly recommended   \n",
       "..               ...                  ...   \n",
       "95                 5    Worth every penny   \n",
       "96                 4          Pretty good   \n",
       "97                 5     Perfect product!   \n",
       "98                 5   Highly recommended   \n",
       "99                 5        Great product   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  I was using Iphone 6s and also Oneplus 6t. Bot...  \n",
       "97  Value for money\\n5 star rating\\nExcellent came...  \n",
       "98  What a camera .....just awesome ..you can feel...  \n",
       "99  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make Data Frame\n",
    "import pandas as pd\n",
    "i_phone=pd.DataFrame({\"I Phone 11 Rating\":Rating,\"I Phone Review\":Review,\"Full Review\":Full_review})\n",
    "i_phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8bf600",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "# search field.\n",
    "# You have to scrape 3 attributes of each sneaker:\n",
    "         1. Brand\n",
    "         2. ProductDescription\n",
    "         3. Price\n",
    "# As shown in the below image, you have to scrape the above attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3aae785",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\" # Here i am assigning the link in url namea variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e519a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the web element for search \"Data Analyst\"\n",
    "search_job=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_job.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b776eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search_btn=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d0ac1ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find 100 Brands name\n",
    "brand=[]\n",
    "\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    Brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for i in Brand:\n",
    "        brand.append(i.text)\n",
    "brand=brand[0:100]\n",
    "len(brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19581bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,3):\n",
    "    Price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in Price:\n",
    "        price.append(i.text)\n",
    "price=price[0:100]\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ef5aea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_des=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    \n",
    "    title_tag=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in title_tag:\n",
    "        prod_des.append(i.text)\n",
    "prod_des=prod_des[0:100]\n",
    "len(prod_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b31e98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sneaker Brank</th>\n",
       "      <th>Sneaker Price</th>\n",
       "      <th>Sneaker Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>₹6,999</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>₹7,699</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>₹499</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>₹279</td>\n",
       "      <td>Latest Exclusive Affordable Collection of Tren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kraasa</td>\n",
       "      <td>₹299</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sneaker Brank Sneaker Price  \\\n",
       "0         UNDER ARMOUR        ₹6,999   \n",
       "1         UNDER ARMOUR        ₹7,699   \n",
       "2                BIRDE          ₹499   \n",
       "3  World Wear Footwear          ₹279   \n",
       "4               Kraasa          ₹299   \n",
       "\n",
       "                                 Sneaker Description  \n",
       "0                                   Sneakers For Men  \n",
       "1                                   Sneakers For Men  \n",
       "2      Combo Pack Of 2 Casual Shoes Sneakers For Men  \n",
       "3  Latest Exclusive Affordable Collection of Tren...  \n",
       "4                                 Sneakers For Women  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make DataFrame\n",
    "import pandas as pd\n",
    "sneaker=pd.DataFrame({\"Sneaker Brank\":brand,\"Sneaker Price\":price,\"Sneaker Description\":prod_des})\n",
    "print(sneaker.shape)\n",
    "sneaker.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f575ba1",
   "metadata": {},
   "source": [
    "# Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "# set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "# After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "              1. Title\n",
    "              2. Ratings\n",
    "              3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37533a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a85b3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the web element for search \"laptop\"\n",
    "laptop=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "laptop.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe97d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3390148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all web elements having Laptop Ratings Done by customer\n",
    "title=[]\n",
    "Title=driver.find_elements(By.XPATH,\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in Title:\n",
    "    title.append(i.text)\n",
    "title=title[0:10]\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "296d28b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all web elements having Ratings given by Customer\n",
    "ratings=[]\n",
    "Rating=driver.find_elements(By.XPATH,\"//span[@class='a-size-base']\")\n",
    "for i in Rating:\n",
    "    ratings.append(i.text)\n",
    "ratings=ratings[0:10]\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2f674a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets extract all web elements having Price\n",
    "price=[]\n",
    "Price=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in Price:\n",
    "    price.append(i.text.split(\"[]\"))\n",
    "price=price[0:10]\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12ec6d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop Title</th>\n",
       "      <th>Laptop Ratings</th>\n",
       "      <th>Laptop Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo V15 AMD Ryzen 3 5300U 15.6\" (39.62cm) F...</td>\n",
       "      <td></td>\n",
       "      <td>[31,389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONOR MagicBook X16 (2023), 12th Gen Intel Cor...</td>\n",
       "      <td></td>\n",
       "      <td>[14,999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo E41-55 Laptop (AMD Athlon Pro 3045B/ 4G...</td>\n",
       "      <td></td>\n",
       "      <td>[22,580]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD...</td>\n",
       "      <td></td>\n",
       "      <td>[40,679]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP 255 G8 Notebook (AMD Ryzen™ 3 3250U/8GB RAM...</td>\n",
       "      <td></td>\n",
       "      <td>[33,989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...</td>\n",
       "      <td></td>\n",
       "      <td>[31,389]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...</td>\n",
       "      <td></td>\n",
       "      <td>[39,989]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...</td>\n",
       "      <td></td>\n",
       "      <td>[28,349]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP 14s, 11th Gen Intel Core i3-1115G4, 8GB RAM...</td>\n",
       "      <td></td>\n",
       "      <td>[4,999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(Renewed) Dell Latitude E5470 Intel Core i5 6t...</td>\n",
       "      <td></td>\n",
       "      <td>[2,700]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Laptop Title Laptop Ratings  \\\n",
       "0  Lenovo V15 AMD Ryzen 3 5300U 15.6\" (39.62cm) F...                  \n",
       "1  HONOR MagicBook X16 (2023), 12th Gen Intel Cor...                  \n",
       "2  Lenovo E41-55 Laptop (AMD Athlon Pro 3045B/ 4G...                  \n",
       "3  HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD...                  \n",
       "4  HP 255 G8 Notebook (AMD Ryzen™ 3 3250U/8GB RAM...                  \n",
       "5  Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...                  \n",
       "6  Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...                  \n",
       "7  HP 15s,11th Gen Intel Core i3-1115G4 8GB RAM/5...                  \n",
       "8  HP 14s, 11th Gen Intel Core i3-1115G4, 8GB RAM...                  \n",
       "9  (Renewed) Dell Latitude E5470 Intel Core i5 6t...                  \n",
       "\n",
       "  Laptop Price  \n",
       "0     [31,389]  \n",
       "1     [14,999]  \n",
       "2     [22,580]  \n",
       "3     [40,679]  \n",
       "4     [33,989]  \n",
       "5     [31,389]  \n",
       "6     [39,989]  \n",
       "7     [28,349]  \n",
       "8      [4,999]  \n",
       "9      [2,700]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make DataFrame\n",
    "import pandas as pd\n",
    "laptop=pd.DataFrame({\"Laptop Title\":title,\"Laptop Ratings\":ratings,\"Laptop Price\":price})\n",
    "laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bba9d1",
   "metadata": {},
   "source": [
    "# Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "# The above task will be done in following steps:\n",
    "                    1. First get the webpagehttps://www.azquotes.com/\n",
    "                    2. Click on TopQuotes\n",
    "                    3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0b8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.azquotes.com/\" # Here i am assigning the link in url namea variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f04f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/h1\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4a631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Lets find 1000 Quotes\n",
    "quote=[]\n",
    "\n",
    "start=0\n",
    "end=1000\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    Quote=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/h1\")\n",
    "    \n",
    "    for i in Quote:\n",
    "        quote.append(i.text)\n",
    "    \n",
    "\n",
    "print(len(quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b01ca98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Lets find author name\n",
    "author=[]\n",
    "\n",
    "start=0\n",
    "end=1000\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    Author=driver.find_elements(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[1]/a\")\n",
    "    \n",
    "    for i in Author:\n",
    "        author.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(len(author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b4e0a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Lets find Typeof Quote\n",
    "top=[]\n",
    "\n",
    "start=0\n",
    "end=1000\n",
    "\n",
    "                         \n",
    "for page in range(start,end):\n",
    "    TOP=driver.find_elements(By.XPATH,\"/html/body\")\n",
    "    \n",
    "    for i in TOP:\n",
    "        top.append(i.text)\n",
    "    \n",
    "    \n",
    "print(len(top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ef40ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Quote</th>\n",
       "      <th>Best Author</th>\n",
       "      <th>Topic of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Quotations by Topic\\nLooking for a quote fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Quotations by Topic\\nLooking for a quote fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Quotations by Topic\\nLooking for a quote fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Quotations by Topic\\nLooking for a quote fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Quote of the Day</td>\n",
       "      <td></td>\n",
       "      <td>Quotations by Topic\\nLooking for a quote fro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Best Quote Best Author  \\\n",
       "0    Quote of the Day               \n",
       "1    Quote of the Day               \n",
       "2    Quote of the Day               \n",
       "3    Quote of the Day               \n",
       "4    Quote of the Day               \n",
       "..                ...         ...   \n",
       "995  Quote of the Day               \n",
       "996  Quote of the Day               \n",
       "997  Quote of the Day               \n",
       "998  Quote of the Day               \n",
       "999  Quote of the Day               \n",
       "\n",
       "                                        Topic of Quote  \n",
       "0      Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...  \n",
       "1      Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...  \n",
       "2      Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...  \n",
       "3      Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...  \n",
       "4      Choose...\\nA\\nB\\nC\\nD\\nE\\nF\\nG\\nH\\nI\\nJ\\nK\\n...  \n",
       "..                                                 ...  \n",
       "995    Quotations by Topic\\nLooking for a quote fro...  \n",
       "996    Quotations by Topic\\nLooking for a quote fro...  \n",
       "997    Quotations by Topic\\nLooking for a quote fro...  \n",
       "998    Quotations by Topic\\nLooking for a quote fro...  \n",
       "999    Quotations by Topic\\nLooking for a quote fro...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets MakeDataFrame\n",
    "import pandas as pd\n",
    "thousand_quote=pd.DataFrame({\"Best Quote\":quote,\"Best Author\":author,\"Topic of Quote\":top})\n",
    "thousand_quote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77262fa",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "# Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "# This task will be done in following steps:\n",
    "                   1. First get the webpagehttps://www.jagranjosh.com/\n",
    "                   2. Then You have to click on the GK option\n",
    "                   3. Then click on the List of all Prime Ministers of India\n",
    "                   4. Then scrap the mentioned data and make theDataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27b4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.jagranjosh.com/\" # Here i am assigning the link in url name variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c96ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "top_quotes=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "top_quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82df069d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find PM name\n",
    "pm_name=[]\n",
    "Names = driver.find_elements(By.XPATH,'//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p')\n",
    "\n",
    "for name in Names:\n",
    "\n",
    "    pm_name.append(name.text)\n",
    "len(pm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b66ba2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find born date and dead date\n",
    "born_dead=[]\n",
    "Born_dead=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr/td[3]/p\")\n",
    "for i in Born_dead:\n",
    "    born_dead.append(i.text)\n",
    "born_dead\n",
    "len(born_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18428724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find term of office\n",
    "tof=[]\n",
    "term_office=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr/td[4]/p[1]\")\n",
    "for i in term_office:\n",
    "    tof.append(i.text)\n",
    "\n",
    "len(tof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f89940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find Remarks\n",
    "remark=[]\n",
    "Remark=driver.find_elements(By.XPATH,\"//div[@class='table-box']/table/tbody/tr/td[5]/p\")\n",
    "for i in Remark:\n",
    "    remark.append(i.text)\n",
    "len(remark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4332806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets make dataframe\n",
    "import pandas as pd\n",
    "all_pm=pd.DataFrame({\"All PM name of india\":pm_name,\"Born-Dead\":born_dead,\"Term of office(Date)\":tof,\"Remark\":remark})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20070586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All PM name of india</th>\n",
       "      <th>Born-Dead</th>\n",
       "      <th>Term of office(Date)</th>\n",
       "      <th>Remark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>2 December 1989 to 10 November 1990</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>10 November 1990 to 21 June 1991</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>21 June 1991 to 16 May 1996</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>16 May 1996 to 1 June 1996</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>1 June 1996 to 21 April 1997</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>21 April 1997 to 19 March 1998</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>19 March 1998 to 22 May 2004</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>22 May 2004 to 26 May 2014</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           All PM name of india     Born-Dead  \\\n",
       "0             Jawahar Lal Nehru   (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)   (1898-1998)   \n",
       "2           Lal Bahadur Shastri   (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)   (1898-1998)   \n",
       "4                 Indira Gandhi   (1917–1984)   \n",
       "5                 Morarji Desai   (1896–1995)   \n",
       "6                  Charan Singh   (1902–1987)   \n",
       "7                 Indira Gandhi   (1917–1984)   \n",
       "8                  Rajiv Gandhi   (1944–1991)   \n",
       "9                   V. P. Singh   (1931–2008)   \n",
       "10              Chandra Shekhar   (1927–2007)   \n",
       "11          P. V. Narasimha Rao   (1921–2004)   \n",
       "12         Atal Bihari Vajpayee  (1924- 2018)   \n",
       "13             H. D. Deve Gowda   (born 1933)   \n",
       "14           Inder Kumar Gujral   (1919–2012)   \n",
       "15         Atal Bihari Vajpayee   (1924-2018)   \n",
       "16               Manmohan Singh   (born 1932)   \n",
       "17                Narendra Modi   (born 1950)   \n",
       "\n",
       "                   Term of office(Date)  \\\n",
       "0         15 August 1947 to 27 May 1964   \n",
       "1           27 May 1964 to 9 June 1964,   \n",
       "2        9 June 1964 to 11 January 1966   \n",
       "3    11 January 1966 to 24 January 1966   \n",
       "4      24 January 1966 to 24 March 1977   \n",
       "5       24 March 1977 to  28 July 1979    \n",
       "6       28 July 1979 to 14 January 1980   \n",
       "7    14 January 1980 to 31 October 1984   \n",
       "8    31 October 1984 to 2 December 1989   \n",
       "9   2 December 1989 to 10 November 1990   \n",
       "10     10 November 1990 to 21 June 1991   \n",
       "11          21 June 1991 to 16 May 1996   \n",
       "12           16 May 1996 to 1 June 1996   \n",
       "13         1 June 1996 to 21 April 1997   \n",
       "14      21 April 1997 to 19 March 1998    \n",
       "15        19 March 1998 to 22 May 2004    \n",
       "16        22 May 2004 to 26 May 2014      \n",
       "17                26 May 2014 - Present   \n",
       "\n",
       "                                               Remark  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9395feb",
   "metadata": {},
   "source": [
    "# Q10: Write s python program to display list of 50 Most expensive cars in the world (i.e. Company name, Model name and Price) from https://www.motor1.com/\n",
    "# This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.motor1.com/\n",
    "\n",
    "2.Then You have to click on the List option from Dropdown menu on left side.\n",
    "\n",
    "3.Then click on 50 most expensive cars in the world..\n",
    "\n",
    "4.Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c61dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.motor1.com/\" # Here i am assigning the link in url name variable \n",
    "driver.get(url) #here using the get method to access the link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4c22ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "three_dots=driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[1]/div\")\n",
    "three_dots.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bdb604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "list_option=driver.find_element(By.XPATH,\"/html/body\")\n",
    "list_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df36039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "most_expensive_car=driver.find_element(By.XPATH,\"/html/body/div[3]/div[5]/h1\")\n",
    "most_expensive_car.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13610731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Find Car Name\n",
    "car_name=[]\n",
    "Car_Name=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for i in Car_Name:\n",
    "    car_name.append(i.text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "car_name=car_name[0:50]\n",
    "len(car_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42fae58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Find Car Price/html/body/div[3]/div[7]/div[2]/div[1]/div[2]/div[1]/p[4]/strong\n",
    "car_price=[]\n",
    "\n",
    "Car_Price=driver.find_elements(By.XPATH,\"/html/body/div[3]/div[7]/div[2]/div[1]/div[2]/div[1]/p[4]\")\n",
    "for i in Car_Price:\n",
    "    car_price.append(i.text)\n",
    "car_price=car_name[0:50]    \n",
    "len(car_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76d4af9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Car Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>De Tomaso P72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Pagani Huayra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>McLaren Elva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Czinger 21C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Car Name          Car Price\n",
       "0      De Tomaso P72      De Tomaso P72\n",
       "1  Ferrari LaFerrari  Ferrari LaFerrari\n",
       "2      Pagani Huayra      Pagani Huayra\n",
       "3       McLaren Elva       McLaren Elva\n",
       "4        Czinger 21C        Czinger 21C"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets Make DataFrame\n",
    "import pandas as pd\n",
    "best_car=pd.DataFrame({\"Car Name\":car_name,\"Car Price\":car_price})\n",
    "print(best_car.shape)\n",
    "best_car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfb646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc1771c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9689baa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
